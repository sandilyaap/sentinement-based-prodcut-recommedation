{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f73b70-f796-4d0f-bcbd-b9620e194053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sandilya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sandilya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sandilya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sandilya/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "from nltk.corpus.reader import reviews\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, string\n",
    "import en_core_web_sm\n",
    "import pickle as pk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf0cf0-2026-48d1-9782-5d184602147d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c7787e-dc92-4ae1-9863-d55de849667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickle files\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle as pk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory path\n",
    "dir_path = \"/Users/sandilya/Desktop/sentiment based product recommendation/\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Load the pickle files\n",
    "count_vector = pk.load(open(os.path.join(dir_path, 'count_vector.pkl'), 'rb'))  # Count Vectorizer\n",
    "tfidf_transformer = pk.load(open(os.path.join(dir_path, 'tfidf_transformer.pkl'), 'rb'))  # TFIDF Transformer\n",
    "model = pk.load(open(os.path.join(dir_path, 'model.pkl'), 'rb'))  # Classification Model\n",
    "recommend_matrix = pk.load(open(os.path.join(dir_path, 'user_final_rating.pkl'), 'rb'))  # User-User Recommendation System\n",
    "\n",
    "# Load the NLP model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
    "\n",
    "# Load the product data\n",
    "product_df = pd.read_csv(\"/Users/sandilya/Desktop/sentiment based product recommendation/sample30.csv\", sep=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "390c9d7f-6734-4c6e-bae6-b6979226a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_characters removal\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    \"\"\"Remove the special Characters\"\"\"\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation_and_splchars(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_word = remove_special_characters(new_word, True)\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "stopword_list= stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopword_list:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation_and_splchars(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "def lemmatize(words):\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return lemmas\n",
    "\n",
    "#predicting the sentiment of the product review comments\n",
    "def model_predict(text):\n",
    "    word_vector = count_vector.transform(text)\n",
    "    tfidf_vector = tfidf_transformer.transform(word_vector)\n",
    "    output = model.predict(tfidf_vector)\n",
    "    return output\n",
    "\n",
    "def normalize_and_lemmaize(input_text):\n",
    "    input_text = remove_special_characters(input_text)\n",
    "    words = nltk.word_tokenize(input_text)\n",
    "    words = normalize(words)\n",
    "    lemmas = lemmatize(words)\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "#Recommend the products based on the sentiment from model\n",
    "def recommend_products(user_name):\n",
    "    recommend_matrix = pk.load(open('pickle_file/user_final_rating.pkl','rb'))\n",
    "    product_list = pd.DataFrame(recommend_matrix.loc[user_name].sort_values(ascending=False)[0:20])\n",
    "    product_frame = product_df[product_df.name.isin(product_list.index.tolist())]\n",
    "    output_df = product_frame[['name','reviews_text']]\n",
    "    output_df['lemmatized_text'] = output_df['reviews_text'].map(lambda text: normalize_and_lemmaize(text))\n",
    "    output_df['predicted_sentiment'] = model_predict(output_df['lemmatized_text'])\n",
    "    return output_df\n",
    "    \n",
    "def top5_products(df):\n",
    "    total_product=df.groupby(['name']).agg('count')\n",
    "    rec_df = df.groupby(['name','predicted_sentiment']).agg('count')\n",
    "    rec_df=rec_df.reset_index()\n",
    "    merge_df = pd.merge(rec_df,total_product['reviews_text'],on='name')\n",
    "    merge_df['%percentage'] = (merge_df['reviews_text_x']/merge_df['reviews_text_y'])*100\n",
    "    merge_df=merge_df.sort_values(ascending=False,by='%percentage')\n",
    "    output_products = pd.DataFrame(merge_df['name'][merge_df['predicted_sentiment'] ==  1][:5])\n",
    "    return output_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39abe1b1-ea64-41b6-925d-5925e51bb3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34380.56s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Package Version\n",
      "------- --------\n",
      "certifi 2024.7.4\n",
      "pip     24.0\n",
      "wheel   0.43.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a535eac-9246-4ed3-9d4b-8c9d1352e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34215.27s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sandilya/Desktop/sentiment based product recommendation/model.py\", line 2, in <module>\n",
      "    from nltk.corpus.reader import reviews\n",
      "ModuleNotFoundError: No module named 'nltk'\n"
     ]
    }
   ],
   "source": [
    "!python3 \"/Users/sandilya/Desktop/sentiment based product recommendation/model.py\"\n",
    "#!python3 -m spacy download en_core_web_sm\n",
    "#! brew upgrade openssl\n",
    "#!python3 -m pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86de3c-6316-434d-9aae-b21e25c0c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d0e86-a6f9-4b6e-ae0d-6e84afee2121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
